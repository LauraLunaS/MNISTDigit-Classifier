{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INL8yqnJPrQs"
   },
   "source": [
    "# Separação de partições com Pytorch sobre o dataset MNIST\n",
    "\n",
    "Complete os códigos onde for solicitado e faça 3 experimentos alterando o tamanho da divisão do dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "executionInfo": {
     "elapsed": 365,
     "status": "ok",
     "timestamp": 1718909738501,
     "user": {
      "displayName": "Laura Luna de Siqueira",
      "userId": "11187402581521684624"
     },
     "user_tz": 180
    },
    "id": "iIhB73C4PzOq"
   },
   "outputs": [],
   "source": [
    "#importando  as bibliotecas\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtjkpGXYVo0f"
   },
   "source": [
    "# Preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "executionInfo": {
     "elapsed": 433,
     "status": "ok",
     "timestamp": 1718909739464,
     "user": {
      "displayName": "Laura Luna de Siqueira",
      "userId": "11187402581521684624"
     },
     "user_tz": 180
    },
    "id": "QI2vzPN2YtjY"
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "mnist_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Defina a proporção de divisão entre treinamento, validação e teste (float)\n",
    "train_ratio = 0.70\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Calcule o tamanho dos conjuntos de treinamento, validação e teste (int)\n",
    "train_size = int(len(mnist_dataset) * train_ratio)\n",
    "val_size = int(len(mnist_dataset) * val_ratio)\n",
    "test_size = int(len(mnist_dataset) * test_ratio)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(mnist_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Mostre o tamanho de cada conjunto\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GaeQBuIaI7z"
   },
   "source": [
    "# Definição da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "executionInfo": {
     "elapsed": 413,
     "status": "ok",
     "timestamp": 1718909743600,
     "user": {
      "displayName": "Laura Luna de Siqueira",
      "userId": "11187402581521684624"
     },
     "user_tz": 180
    },
    "id": "jRlRmTiTZCHT"
   },
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1718909744618,
     "user": {
      "displayName": "Laura Luna de Siqueira",
      "userId": "11187402581521684624"
     },
     "user_tz": 180
    },
    "id": "KAON_ycUUczl"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, epoch=1):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "    for epoch in range(epoch):\n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                inputs, labels = data\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = val_correct / val_total\n",
    "        print(f'Epoch {epoch + 1}, Validation Accuracy: {val_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "executionInfo": {
     "elapsed": 393,
     "status": "ok",
     "timestamp": 1718909747160,
     "user": {
      "displayName": "Laura Luna de Siqueira",
      "userId": "11187402581521684624"
     },
     "user_tz": 180
    },
    "id": "rrXIpyA-WEBr"
   },
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "  model.eval()\n",
    "  test_correct = 0\n",
    "  test_total = 0\n",
    "  with torch.no_grad():\n",
    "      for data in test_loader:\n",
    "          inputs, labels = data\n",
    "          outputs = model(inputs)\n",
    "          _, predicted = torch.max(outputs.data, 1)\n",
    "          test_total += labels.size(0)\n",
    "          test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "  test_accuracy = test_correct / test_total\n",
    "  print(f'Neural Network Test Accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOw4LL0FaMWH"
   },
   "source": [
    "# Uso da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 82675,
     "status": "ok",
     "timestamp": 1718909832784,
     "user": {
      "displayName": "Laura Luna de Siqueira",
      "userId": "11187402581521684624"
     },
     "user_tz": 180
    },
    "id": "QMqX7ufqZXfE",
    "outputId": "4d2613c9-4294-485c-daa4-a02d05034a60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando Rede Neural Simples:\n",
      "Epoch 1, Validation Accuracy: 0.9302222222222222\n",
      "Epoch 2, Validation Accuracy: 0.9482222222222222\n",
      "Epoch 3, Validation Accuracy: 0.9513333333333334\n",
      "Epoch 4, Validation Accuracy: 0.9604444444444444\n",
      "Epoch 5, Validation Accuracy: 0.9665555555555555\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNN()\n",
    "\n",
    "print(\"Treinando Rede Neural Simples:\")\n",
    "# Treine a rede neural simples\n",
    "\n",
    "print(train(model, train_loader, val_loader, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3216,
     "status": "ok",
     "timestamp": 1718909835967,
     "user": {
      "displayName": "Laura Luna de Siqueira",
      "userId": "11187402581521684624"
     },
     "user_tz": 180
    },
    "id": "JBDCQOejXGPj",
    "outputId": "eb59c885-6200-4a68-eb38-e277202fa0df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Test Accuracy: 0.9618888888888889\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Avalie a rede neural simples\n",
    "# Sua acurácia deve ser maior que 0.96\n",
    "print(test(model, test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CWgqjjKkvIf"
   },
   "source": [
    "Descreva aqui os 3 experimentos executados e quais foram os resultados obtidos em cada um deles:\n",
    "\n",
    "\n",
    "**Primeiro experimento:**\n",
    "\n",
    "train_ratio = 0.60\n",
    "val_ratio = 0.25\n",
    "test_ratio = 0.15\n",
    "\n",
    "print(train(model, train_loader, val_loader, 6))\n",
    "\n",
    "\n",
    "Treinando Rede Neural Simples:\n",
    "Epoch 1, Validation Accuracy: 0.9210666666666667\n",
    "Epoch 2, Validation Accuracy: 0.9468\n",
    "Epoch 3, Validation Accuracy: 0.9516\n",
    "Epoch 4, Validation Accuracy: 0.9499333333333333\n",
    "Epoch 5, Validation Accuracy: 0.9572\n",
    "Epoch 6, Validation Accuracy: 0.9645333333333334\n",
    "\n",
    "Neural Network Test Accuracy: 0.9673333333333334\n",
    "\n",
    "\n",
    "**Segundo experimento:**\n",
    "\n",
    "train_ratio = 0.70\n",
    "val_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "print(train(model, train_loader, val_loader, 6))\n",
    "\n",
    "Treinando Rede Neural Simples:\n",
    "Epoch 1, Validation Accuracy: 0.9205555555555556\n",
    "Epoch 2, Validation Accuracy: 0.949\n",
    "Epoch 3, Validation Accuracy: 0.9514444444444444\n",
    "Epoch 4, Validation Accuracy: 0.9601111111111111\n",
    "Epoch 5, Validation Accuracy: 0.9678888888888889\n",
    "Epoch 6, Validation Accuracy: 0.9664444444444444\n",
    "\n",
    "\n",
    "Neural Network Test Accuracy: 0.9666666666666667\n",
    "\n",
    "**Terceiro experimento:**\n",
    "\n",
    "train_ratio = 0.70\n",
    "val_ratio = 0.10\n",
    "test_ratio = 0.20\n",
    "\n",
    "print(train(model, train_loader, val_loader, 4))\n",
    "\n",
    "Treinando Rede Neural Simples:\n",
    "Epoch 1, Validation Accuracy: 0.9251666666666667\n",
    "Epoch 2, Validation Accuracy: 0.9415\n",
    "Epoch 3, Validation Accuracy: 0.9553333333333334\n",
    "Epoch 4, Validation Accuracy: 0.948\n",
    "\n",
    "\n",
    "Neural Network Test Accuracy: 0.9501666666666667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZopxUKCuO3-"
   },
   "source": [
    "# Métricas da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5554,
     "status": "ok",
     "timestamp": 1718910539567,
     "user": {
      "displayName": "Laura Luna de Siqueira",
      "userId": "11187402581521684624"
     },
     "user_tz": 180
    },
    "id": "dleGEbu6uRgj",
    "outputId": "f1c4070f-16d2-4cab-e572-28137dce8b45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 895    0    4    1    2    1    1    2    3    1]\n",
      " [   0 1009    8    0    3    0    0    3    3    1]\n",
      " [   3    5  827    2    4    0    1    5    9    0]\n",
      " [   2    7   13  865    1   12    1    7   16    6]\n",
      " [   0    2    1    0  898    0    5    2    2    3]\n",
      " [   6    3    5    6    1  747    5    1    8    3]\n",
      " [   7    1    5    0    7    4  846    0    7    0]\n",
      " [   1    3    4    0   11    0    0  948    1    8]\n",
      " [   3   10    4    5    6    7    1    1  789   10]\n",
      " [   1    3    0    6   26    5    0   13    3  833]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Criando uma matriz de confusão\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# Obtendo as previsões e rótulos reais no dataset\n",
    "for inputs, labels in test_loader:\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    y_pred.extend(predicted.tolist())\n",
    "    y_true.extend(labels.tolist())\n",
    "\n",
    "# Converção das listas para arrays NumPy\n",
    "y_pred = np.array(y_pred)\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "# Criando a matriz de confusão\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Imprimimindo a matriz de confusão\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 372,
     "status": "ok",
     "timestamp": 1718911921113,
     "user": {
      "displayName": "Laura Luna de Siqueira",
      "userId": "11187402581521684624"
     },
     "user_tz": 180
    },
    "id": "IceQ0szkB1Mz",
    "outputId": "b3b7b407-f409-4c11-f6dd-f3024625e226"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A precisão da classe 1, foi de: 0.9835164835164835\n",
      "A precisão da classe 2, foi de: 0.9824732229795521\n",
      "A precisão da classe 3, foi de: 0.9661214953271028\n",
      "A precisão da classe 4, foi de: 0.9301075268817204\n",
      "A precisão da classe 5, foi de: 0.9835706462212487\n",
      "A precisão da classe 6, foi de: 0.9515923566878981\n",
      "A precisão da classe 7, foi de: 0.9646522234891676\n",
      "A precisão da classe 8, foi de: 0.9713114754098361\n",
      "A precisão da classe 9, foi de: 0.94377990430622\n",
      "A precisão da classe 10, foi de: 0.9359550561797753\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cm)):\n",
    "  print(f'A precisão da classe {i+1}, foi de: {cm[i][i] / sum(cm[i])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1718911922114,
     "user": {
      "displayName": "Laura Luna de Siqueira",
      "userId": "11187402581521684624"
     },
     "user_tz": 180
    },
    "id": "SyqId-GlGDIi",
    "outputId": "3a671ff8-66af-4318-d99b-1d7ff06e7443"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall da classe 1, foi de: 0.9749455337690632\n",
      "Recall da classe 2, foi de: 0.9674017257909875\n",
      "Recall da classe 3, foi de: 0.9494833524684271\n",
      "Recall da classe 4, foi de: 0.9774011299435028\n",
      "Recall da classe 5, foi de: 0.9363920750782064\n",
      "Recall da classe 6, foi de: 0.9626288659793815\n",
      "Recall da classe 7, foi de: 0.9837209302325581\n",
      "Recall da classe 8, foi de: 0.9653767820773931\n",
      "Recall da classe 9, foi de: 0.9381688466111772\n",
      "Recall da classe 10, foi de: 0.9630057803468208\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cm)):\n",
    "  print(f'Recall da classe {i+1}, foi de: {cm[i][i] / sum(cm[:, i])}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1vZn1IUzyf8H6CqsbUAZ3ICeDu2S-zaWM",
     "timestamp": 1718905679509
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
